---
layout: post
title:  "Metropolis, Monte-Carlo, and Sampling The Posterior Distribution"
date:   2014-10-21
categories: bayesian
---

Most books that provide introduction to Bayesian Analysis show examples of problems which are designed to give you a feel for simple Bayesian analysis. Coin flippings problems, for example, are usually seeded with Beta priors which are conveniently conjungate the the likelihood function. This is great for learning the basics, as it yields a simple analytically solvable posterior distribution. Unfortunately, as you move on to applying Bayesian analysis to real world problems, there are many situtions in which simple methods will not work. For example, some times your prior beliefs about a model cannot be adequately modeled using a Beta distribution (or by any other function that would yield an analytically solvable posterior distribution). 

[Grid approximation](http://www.people.fas.harvard.edu/~plam/teaching/methods/grid/grid_print.pdf) is a standard example which works well in 1-D space, but as the number of different parameters in your model increase, becomes unfesiable. The following provides a set of tools were developed for just this situation. Of important note though, everything below assumes that the numerator in Bayes equation (likelihood * prior) can be evaluated at **any possible value**.	The goal of these methods is to produce an **approximation** of the posterior distribution by taking random samples from it. Assume the sample size is large enough (and dispersed correctly), the samples can be used to calculate summary statistics such as mean, median, credability intervals, etc.

Enter the [Metrpolis algorithm](http://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) (as known as the Metrpolis-Hastings algorithm).	Developed in 1953, this algorithm is Markov Chain method for obtaining a sequence of random samples from a probability distribution for which direct sampling is difficult.

My favorite description of how the Metrpolis algorithm works comes from "Doing Bayesian Analysis":	

>Suppose an elected politician lives on a long chain of islands. He is constantly traveling from island to island, wanting to stay in the public eye. At the end of a grueling day of photo opportunities and fundraising1, he has to decide whether to (i) stay on the current island, (ii) move to the adjacent island to the west, or (iii) move to the adjacent island to the east. His goal is to visit all the islands proportionally to their relative population, so that he spends the most time on the most populated islands, and proportionally less time on the less populated islands. Unfortunately, he holds his office despite having no idea what the total population of the island chain is, and he doesn’t even know exactly how many islands there are! His entourage of advisers is capable of some minimal information gathering abilities, however. When they are not busy fundraising, they can ask the mayor of the island they are on how many people are on the island. And, when the politician proposes to visit an adjacent island, they can ask the mayor of that adjacent island how many people are on that island.

>The politician has a simple heuristic for deciding whether to travel to the proposed island: First, he flips a (fair) coin to decide whether to propose the adjacent island to the east or the adjacent island to the west. If the proposed island has a larger population than the current island, then he definitely goes to the proposed island. On the other hand, if the proposed island has a smaller population than the current island, then he goes to the proposed island only probabilistically, to the extent that the proposed island has a population as big as the current island. In more detail, denote the population of the proposed island as Pproposed, and the population of the current island as Pcurrent. Then he moves to the less populated island with probability pmove = Pproposed/Pcurrent. The politician does this by spinning a fair spinner marked on its circumference with uniform values from zero to one. If the pointed-to value is between zero and pmove, then he moves. What’s amazing about this heuristic is that it works: In the long run, the probability that the politician is on any one of the islands in the chain exactly matches the relative population of the island!


